{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb1587d",
   "metadata": {},
   "source": [
    "# Importing some packages and setting params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59f32b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "_ = load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "LLM_API = os.getenv('LLM_API')\n",
    "\n",
    "BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "MODEL = 'meta-llama/llama-3.3-70b-instruct:free'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d5245b",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5826d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "\n",
    "    data_loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob='*.pdf',\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "    documents = data_loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "094f1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_file('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd98a1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4505"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51f02a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_chunks(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fecc20d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks = get_text_chunks(extracted_data)\n",
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b92b5d",
   "metadata": {},
   "source": [
    "# Vectorizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d502b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hf_embeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "461ba33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vchar\\AppData\\Local\\Temp\\ipykernel_45464\\2220663536.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hf_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d665c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query('Hello world!')\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d2f80",
   "metadata": {},
   "source": [
    "# Sending data to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011968eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medical-bot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    " \n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\",\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f2696a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d710719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docsearch = PineconeVectoreStore.from_existing_index(\n",
    "#     index_name=index_name,\n",
    "#     embedding=embeddings\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf5f6473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='4cc333f0-4759-46d5-9c5c-95b22e26757f', metadata={'creationdate': 'D:20251225102511', 'creator': 'PDFium', 'page': 55.0, 'page_label': '56', 'producer': 'PDFium', 'source': '..\\\\data\\\\The_Gale_Encyclopedia_of_Medicine.pdf', 'total_pages': 4505.0}, page_content='Researchers, Inc. Reproduced by permission.)\\n26 GALE ENCYCLOPEDIA OF MEDICINE\\nAcne'),\n",
       " Document(id='d809e57e-6c10-4ca6-8248-e06968553c74', metadata={'creationdate': 'D:20251225102511', 'creator': 'PDFium', 'page': 55.0, 'page_label': '56', 'producer': 'PDFium', 'source': '..\\\\data\\\\The_Gale_Encyclopedia_of_Medicine.pdf', 'total_pages': 4505.0}, page_content='Sebaceous follicles— A structure found within the\\nskin that houses the oil-producing glands and hair\\nfollicles, where pimples form.\\nSebum— An oily skin moisturizer produced by\\nsebaceous glands.\\nTretinoin— A drug that works by increasing the\\nturnover (death and replacement) of skin cells.\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous glands\\nbecome inflamed. (Photograph by Biophoto Associates, Photo'),\n",
       " Document(id='e7503fe9-37bb-4a25-b600-25c0610ea109', metadata={'creationdate': 'D:20251225102511', 'creator': 'PDFium', 'page': 54.0, 'page_label': '55', 'producer': 'PDFium', 'source': '..\\\\data\\\\The_Gale_Encyclopedia_of_Medicine.pdf', 'total_pages': 4505.0}, page_content='Pathological Stage and Recurrence in Radical\\nProstatectomy Cases.’’Journal of Urology (March\\n1998): 935-940.\\nNancy J. Nordenson\\nAcid reflux see Heartburn\\nAcidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when\\nthe pores of the skin become clogged with oil, dead\\nskin cells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne,')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever =docsearch.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "retrieved_docs = retriever.invoke('What is Acne?')\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853eccb",
   "metadata": {},
   "source": [
    "# Applying LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "408e9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    base_url=BASE_URL,\n",
    "    api_key=LLM_API,\n",
    "    model=MODEL,\n",
    "    temperature=0.4,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# llm = OpenAI(\n",
    "#     base_url=BASE_URL,\n",
    "#     api_key=LLM_API,\n",
    "#     model=MODEL,\n",
    "#     temperature=0.4,\n",
    "#     max_tokens=500\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "061b4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for a question answering tasks.\"\n",
    "    \"Use the following pieces of retrieved context to answer\"\n",
    "    \"a question, if you don't know the answer, say that you\"\n",
    "    \"don't know. Use 3 sentences at max to answer and be as\"\n",
    "    \"concise as possible.\\n\\n{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', system_prompt),\n",
    "        ('human', '{input}')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0df669e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever, \"input\": RunnablePassthrough()}  # Step 1: Retrieve context, pass input through\n",
    "    | prompt                                                # Step 2: Format prompt with context + input\n",
    "    | llm                                                   # Step 3: Call the LLM\n",
    "    | StrOutputParser()                                     # Step 4: Extract the string from the LLM response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "612c3f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acne is a common skin disease characterized by pimples on the face, chest, and back. It occurs when the pores of the skin become clogged with oil, dead skin cells, and bacteria. Acne vulgaris is the medical term for common acne.\n"
     ]
    }
   ],
   "source": [
    "# Invoke it\n",
    "response = rag_chain.invoke('What is Acne?')\n",
    "print(response)  # Directly prints the answer string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da79b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
